{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0dbe52-bce7-4ad8-9875-2b65e69778f5",
   "metadata": {},
   "source": [
    "<h1><center>MACHINE LEARNING</center></h1>\n",
    "<center><img src=\"https://www.fsm.ac.in/blog/wp-content/uploads/2022/08/ml-e1610553826718.jpg\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a355e4-dc10-4b4e-989c-5fdae8bbafa9",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Welcome to \"Data Science with Machine Learning,\" your practical guide to unlocking insights from data using cutting-edge machine learning techniques. In today's data-driven world, organizations across industries are leveraging the power of data science and machine learning to extract valuable insights, make informed decisions, and drive innovation.\n",
    "\n",
    "This notebook is designed to provide you with a hands-on approach to mastering the intersection of data science and machine learning. Whether you're a beginner looking to build a solid foundation in data science principles or an experienced practitioner seeking advanced techniques and strategies, this notebook will equip you with the skills and knowledge you need to succeed in today's competitive landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d8b2f-52fb-420e-96ca-9458558a211a",
   "metadata": {},
   "source": [
    "## What is Machine Learning\n",
    "Machine Learning is a subset of artificial intelligence that focuses on building systems that can learn from data. The goal is to enable computers to make predictions or decisions without being explicitly programmed.\n",
    "## Machine Learning Chat\n",
    "![Image](https://miro.medium.com/v2/resize:fit:720/format:webp/0*botktOR526S9maYd)\n",
    "## Types of Machine Learning\n",
    "1. **Supervised Learning**: In supervised learning, the algorithm learns from labeled data, which means it's provided with input-output pairs. The goal is to learn a mapping from inputs to outputs, so when presented with new, unseen data, it can predict the correct output. Common algorithms in supervised learning include linear regression, decision trees, support vector machines (SVM), and neural networks.\n",
    "![Image](https://databasetown.com/wp-content/uploads/2023/05/Supervised-Learning-1024x726.jpg)\n",
    "2. **Unsupervised Learning**: Unsupervised learning involves learning from unlabeled data. The algorithm tries to find patterns or intrinsic structures in the input data. Clustering and dimensionality reduction are typical tasks in unsupervised learning. Clustering algorithms like k-means, hierarchical clustering, and density-based clustering, along with dimensionality reduction techniques like principal component analysis (PCA) and t-distributed stochastic neighbor embedding (t-SNE), fall under this category.\n",
    "![Image](https://databasetown.com/wp-content/uploads/2023/05/Unsupervised-Learning-1024x726.jpg)\n",
    "3. **Reinforcement Learning**: Reinforcement learning (RL) is about learning to make decisions sequentially. It learns from feedback in the form of rewards or punishments. The agent, which makes decisions, interacts with an environment and learns to choose actions that maximize cumulative reward over time. Reinforcement learning has been successfully applied in various domains such as game playing, robotics, and autonomous vehicle control.\n",
    "Algorithms like Q-learning, deep Q-networks (DQN), and policy gradients are commonly used in reinforcement learning.\n",
    "![Image](https://www.3nions.com/wp-content/uploads/2021/03/Reinforcement-Learning-in-ML-TV.jpeg)\n",
    "These categories are not mutually exclusive, and there are also hybrid approaches that combine elements of these types, such as semi-supervised learning, where the algorithm learns from a combination of labeled and unlabeled data. Additionally, there are specialized forms of learning, such as online learning and transfer learning, which adapt the learning process to specific scenarios and tasks.\n",
    "## AI Machine Learning\n",
    "It is important to note that Machine Learning(ML), is a subset of Artificial Intelligence(AI). Deep Learning(DL) in turn, is a subset of Machine Learning(ML). But both ML and DL are subsets of AI\n",
    "![Image](https://idm.net.au/sites/idm.net.au/files/Hexagon1-600.png)\n",
    "## Tools for implementing ML\n",
    "- Pandas:- for manipulating and analysis, offers data structures like DataFrames that are crucial for handling structured data\n",
    "- Numpy:- fundamental package for scientific computing in python, provides support for multi dimensional arrays and matrices\n",
    "- Matplotlib:- 2D plotting library for creating static, animated and interactive visualization. Also useful for visualizing data and model performance\n",
    "- Seaborn:- built on Matplotlib, it provides high-level interface for statistical data visualization. Also simplifies creating information and attractive statistical graphics\n",
    "- Scikit-Learn:- provides simple and efficient tools for data mining and data analysis. Also includes various machine learning algorithms for classification, regression, clustering, and more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a147ea-6701-4f79-9ff0-bba202f99b7c",
   "metadata": {},
   "source": [
    "# What is Scikit-Learn?\n",
    "Scikit-learn is an open source library in Python. Scikit-learn ia a python programming library which is sed to implement machine learning models. It was previously known as scikits.learn and was created in 2007 as a google summer of code project by David Cournapeau.\n",
    "Along with scikit-learn, we will be using few other libraries such as numpy, pandas and matplotlib.\n",
    "## What kind of Dataset won't be recognized by Scikit Learn\n",
    "A dataset that won't work well for scikit-learn is one with missing values or NaNs (Not a Number) that haven't been handled or imputed. Scikit-learn's algorithms typically expect complete datasets with no missing values. If your dataset has missing values, you'll need to preprocess it by either imputing the missing values (replacing them with estimated values based on other data points) or removing the rows or columns with missing values. Otherwise, scikit-learn algorithms may throw errors or produce unreliable results. You can fill missing values using Pandas and also with Scikit Learn\n",
    "## Scikit Learn Workflow\n",
    "- Get data ready\n",
    "- Pick a model to suit your problem\n",
    "- Fit the model to the data and make predictions\n",
    "- Evaluate the model\n",
    "- Improve through experimentation\n",
    "- Save!!!\n",
    "## Where Can You Get Help?\n",
    "- Follow along with the code\n",
    "- Try it yourself\n",
    "- press Shift+Tab to learn from the docstring on Jupyter notebook\n",
    "- Search for it using Stack Overflow and/or reading the documentation of the library\n",
    "- Try again\n",
    "- Ask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4581a1-2b45-4243-99f9-64c20f62bd6a",
   "metadata": {},
   "source": [
    "# Choosing the Right Model for your Data\n",
    "![image](https://scikit-learn.org/stable/_static/ml_map.png)\n",
    "\n",
    "Scikit Learn Documentation: https://scikit-learn.org/stable/tutorial/index.html\n",
    "\n",
    "Based on this diagram, we are able to see the flow of the chat. This will guide you to an extent on the right model to use for your dataset. Lets have an example use case below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a23b7-a6de-47a8-93bc-f7c149f2ccc1",
   "metadata": {},
   "source": [
    "## Use Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a214360-2f5f-4605-963d-9979e4e58f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "print(housing.data.shape, housing.target.shape)\n",
    "print(housing.feature_names[0:6],'\\n')\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a7f5aa-5af0-49ae-af8b-bfa2af4f3a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets turn this into a DataFrame so it will be easier to use and understand\n",
    "import pandas as pd\n",
    "housing_df = pd.DataFrame(housing['data'], columns=housing['feature_names'])\n",
    "housing_df['target'] = housing['target']\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3045e1d-5731-4c92-9200-f02b7856a40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758549611440142"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have our dataset visible and easier to understand, we start oue exercise\n",
    "# import algorithm\n",
    "\n",
    "#setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# extracting the dependent and independent variables\n",
    "x = housing_df.iloc[:, :-1].values\n",
    "y = housing_df.iloc[:, 8].values\n",
    "\n",
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# Now this is the moment\n",
    "# Moment to figure out which model to use for this dataset\n",
    "# Go back to the Picture/Map above. You will see a circle labelled START.\n",
    "# That is where you start from.\n",
    "# Now i will work you through step by step from the beginning.\n",
    "\n",
    "# From the circle labelled START, when you follow the arrow down, it says >50 samples. This is asking if our Dataset has more than 50 samples/Row. In our case it is YES\n",
    "# Now we follow the arrow that says YES, we now have PREDICTING CATEGORY, meaning Are we Predicting category?. In our case it is NO\n",
    "# Now we follow the arrow that says NO, we now have PREDICTING QUANTITY, meaning Are we predicting quantity?. In our case it is Yes\n",
    "# Now this takes us straight to the REGRESSION MODEL AREA.\n",
    "# Following the arrow again, it says <100k samples. This is asking if our Dataset has less than 100k samples/rows. In our case it is Yes\n",
    "# Then you pick the Model\n",
    "\n",
    "# Based on the chat, ill be picking the Rigde regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "# fitting Ridge Regression to the Training set\n",
    "model = Ridge() # creates an instance of Ridge regression\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# check the score of the model on the test set\n",
    "model.score(x_test, y_test)\n",
    "\n",
    "# From the score we got (0.5758549611440142), is pretty low. We should be aiming for 0.8 and above. Well, up to 1.0 anyways\n",
    "# So, because of the low score, we use another model and based on the chat, the next option model wound be SVR(Kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bedf8258-f0cf-4d0e-a97c-d744d2d8ba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71923978 1.76395141 2.70909238 ... 4.46864495 1.18785499 2.00912494]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "print(y_pred)\n",
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e34724b-3542-45fd-b335-8b9531dea002",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Ridge' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred_pro \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(x_test)\n\u001b[0;32m      2\u001b[0m y_pred_pro\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Ridge' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "# getting the predictive probability\n",
    "# but unfortunately, Ridge model does not have the attribute 'Predict_proba'\n",
    "y_pred_pro = model.predict_proba(x_test)\n",
    "y_pred_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8f920a-ca48-4b7d-82f0-a44a70d3f184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Import necessary libraries\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.svm import SVR  # Import SVR for regression\\n\\n# Set random seed\\nnp.random.seed(42)\\n\\n# Assuming \\'housing_df\\' is your DataFrame containing the dataset\\n\\n# Extracting the dependent and independent variables\\nx = housing_df.iloc[:, :-1].values\\ny = housing_df.iloc[:, -1].values  # Assuming the last column is the target variable\\n\\n# Splitting into train and test sets\\ntry:\\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\\nexcept ValueError as e:\\n    print(\"Error:\", e)\\n    # Add additional error handling or modify the code accordingly\\n\\n# Creating and training the model\\ntry:\\n    model = SVR(kernel=\\'linear\\', C=1)  # Use SVR for regression\\n    model.fit(x_train, y_train)\\nexcept ValueError as e:\\n    print(\"Error:\", e)\\n    # Add additional error handling or modify the code accordingly\\nelse:\\n    # Evaluating the model\\n    score = model.score(x_test, y_test)\\n    print(\"R-squared Score:\", score)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR  # Import SVR for regression\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming 'housing_df' is your DataFrame containing the dataset\n",
    "\n",
    "# Extracting the dependent and independent variables\n",
    "x = housing_df.iloc[:, :-1].values\n",
    "y = housing_df.iloc[:, -1].values  # Assuming the last column is the target variable\n",
    "\n",
    "# Splitting into train and test sets\n",
    "try:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)\n",
    "    # Add additional error handling or modify the code accordingly\n",
    "\n",
    "# Creating and training the model\n",
    "try:\n",
    "    model = SVR(kernel='linear', C=1)  # Use SVR for regression\n",
    "    model.fit(x_train, y_train)\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)\n",
    "    # Add additional error handling or modify the code accordingly\n",
    "else:\n",
    "    # Evaluating the model\n",
    "    score = model.score(x_test, y_test)\n",
    "    print(\"R-squared Score:\", score)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130630b6-4725-419c-9c37-13bb0de870a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Import necessary libraries\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.svm import SVR  # Import SVR for regression\\n\\n# Set random seed\\nnp.random.seed(42)\\n\\n# Assuming \\'housing_df\\' is your DataFrame containing the dataset\\n\\n# Extracting the dependent and independent variables\\nx = housing_df.iloc[:, :-1].values\\ny = housing_df.iloc[:, -1].values  # Assuming the last column is the target variable\\n\\n# Splitting into train and test sets\\ntry:\\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\\nexcept ValueError as e:\\n    print(\"Error:\", e)\\n    # Add additional error handling or modify the code accordingly\\n\\n# Creating and training the model\\ntry:\\n    model = SVR(kernel=\\'rbf\\', C=1)  # Use SVR for regression\\n    model.fit(x_train, y_train)\\nexcept ValueError as e:\\n    print(\"Error:\", e)\\n    # Add additional error handling or modify the code accordingly\\nelse:\\n    # Evaluating the model\\n    score = model.score(x_test, y_test)\\n    print(\"R-squared Score:\", score)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR  # Import SVR for regression\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming 'housing_df' is your DataFrame containing the dataset\n",
    "\n",
    "# Extracting the dependent and independent variables\n",
    "x = housing_df.iloc[:, :-1].values\n",
    "y = housing_df.iloc[:, -1].values  # Assuming the last column is the target variable\n",
    "\n",
    "# Splitting into train and test sets\n",
    "try:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)\n",
    "    # Add additional error handling or modify the code accordingly\n",
    "\n",
    "# Creating and training the model\n",
    "try:\n",
    "    model = SVR(kernel='rbf', C=1)  # Use SVR for regression\n",
    "    model.fit(x_train, y_train)\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)\n",
    "    # Add additional error handling or modify the code accordingly\n",
    "else:\n",
    "    # Evaluating the model\n",
    "    score = model.score(x_test, y_test)\n",
    "    print(\"R-squared Score:\", score)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3103cc04-7b1e-41ad-bc67-f2d46adc4652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Import necessary libraries\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import HistGradientBoostingRegressor  # Use regression model\\n\\n# Set random seed\\nnp.random.seed(42)\\n\\n# Assuming \\'housing_df\\' is your DataFrame containing the dataset\\n\\n# Extracting the dependent and independent variables\\nx = housing_df.iloc[:, :-1].values\\ny = housing_df.iloc[:, -1].values  # Assuming the last column is the target variable\\n\\n# Splitting into train and test sets\\ntry:\\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\\nexcept ValueError as e:\\n    print(\"Error:\", e)\\n    # Add additional error handling or modify the code accordingly\\n\\n# Creating and training the model\\ntry:\\n    model = HistGradientBoostingRegressor(max_iter=100)  # Use regression model\\n    model.fit(x_train, y_train)\\nexcept ValueError as e:\\n    print(\"Error:\", e)\\n    # Add additional error handling or modify the code accordingly\\nelse:\\n    # Evaluating the model\\n    score = model.score(x_test, y_test)\\n    print(\"R-squared Score:\", score)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor  # Use regression model\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Assuming 'housing_df' is your DataFrame containing the dataset\n",
    "\n",
    "# Extracting the dependent and independent variables\n",
    "x = housing_df.iloc[:, :-1].values\n",
    "y = housing_df.iloc[:, -1].values  # Assuming the last column is the target variable\n",
    "\n",
    "# Splitting into train and test sets\n",
    "try:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)\n",
    "    # Add additional error handling or modify the code accordingly\n",
    "\n",
    "# Creating and training the model\n",
    "try:\n",
    "    model = HistGradientBoostingRegressor(max_iter=100)  # Use regression model\n",
    "    model.fit(x_train, y_train)\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)\n",
    "    # Add additional error handling or modify the code accordingly\n",
    "else:\n",
    "    # Evaluating the model\n",
    "    score = model.score(x_test, y_test)\n",
    "    print(\"R-squared Score:\", score)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a18e8-ab53-4269-a13d-900e9fdb39a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493101f-c8e5-4b21-b491-80d309a23ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
