{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5278c5b-8ac8-4bf0-9c9f-b9e08e860838",
   "metadata": {},
   "source": [
    "### Learning Guide\n",
    "1. What is K Nearest Neigbour?\n",
    "2. Why do we need KNN?\n",
    "3. How do we choose the K factor?\n",
    "4. When do we use KNN?\n",
    "5. How does KNN algorithm work?\n",
    "6. Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c131ba-97c1-47ef-b80a-de5bdbc50346",
   "metadata": {},
   "source": [
    "## What is K Nearest Neigbour\n",
    "K Nearest Neighbors (KNN) is a simple and intuitive supervised machine learning algorithm used for both classification and regression tasks. It is a non-parametric method that makes predictions based on the majority vote of its k nearest neighbors in the feature space.\n",
    "![image](https://static.javatpoint.com/tutorial/machine-learning/images/k-nearest-neighbor-algorithm-for-machine-learning2.png)\n",
    "![image](https://miro.medium.com/v2/resize:fit:720/format:webp/0*Rxd_UYjOPrK7_gk4)\n",
    "## Why do we need KNN?\n",
    "K Nearest Neighbors (KNN) is a valuable machine learning algorithm for several reasons:\r\n",
    "\r\n",
    "1. **Simplicity**: KNN is easy to understand and implement, making it accessible even for beginners in machine learning.\r\n",
    "\r\n",
    "2. **Versatility**: KNN can be applied to both classification and regression tasks. It is effective in scenarios where the relationship between features and target variables is not explicitly defined.\r\n",
    "\r\n",
    "3. **No Training Phase**: KNN is a lazy learner, meaning it does not require a training phase. Instead, it stores all the training data and makes predictions at runtime based on the stored information.\r\n",
    "\r\n",
    "4. **Adaptability**: KNN can adapt to changes in the dataset without the need for retraining. This makes it suitable for dynamic environments where data distribution may change over time.\r\n",
    "\r\n",
    "5. **Non-parametric**: KNN does not make any assumptions about the underlying data distribution and does not estimate parameters from the data. This makes it robust and applicable to various types of data.\r\n",
    "\r\n",
    "6. **Interpretability**: KNN provides straightforward interpretations of predictions. For classification tasks, the predicted class is determined by the majority class among the nearest neighbors. For regression tasks, the predicted value is the average (or weighted average) of the target values of the nearest neighbors.\r\n",
    "\r\n",
    "7. **Effective for Small to Medium-Sized Datasets**: KNN performs well on datasets with a moderate number of features and samples. It can handle complex decision boundaries and is particularly effective when the dataset is not too large.\r\n",
    "\r\n",
    "8. **Handles Multi-Class Classification**: KNN naturally extends to multi-class classification tasks by considering the majority class among the k ne\n",
    "al-world problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd96313b-6415-48d9-bad0-6cafb74ceeb4",
   "metadata": {},
   "source": [
    "## How do we choose the K factor?\n",
    "Choosing the appropriate value of the hyperparameter \\( k \\) in K Nearest Neighbors (KNN) is crucial for the performance of the algorithm. The choice of \\( k \\) affects the model's ability to generalize to unseen data, the smoothness of the decision boundary, and the trade-off between bias and variance. Here are some common approaches to choose the value of \\( k \\):\r\n",
    "\r\n",
    "1. **Grid Search**: Perform a grid search over a range of \\( k \\) values and select the one that results in the highest cross-validated accuracy (or another appropriate evaluation metric). This method is computationally expensive but provides an exhaustive search over the hyperparameter space.\r\n",
    "\r\n",
    "2. **Cross-Validation**: Use \\( k \\)-fold cross-validation to evaluate the performance of the KNN model for different values of \\( k \\). Choose the \\( k \\) value that yields the best average performance across the folds. This approach helps in assessing the model's generalization ability and reduces the risk of overfitting.\r\n",
    "\r\n",
    "3. **Odd vs. Even Values**: When \\( k \\) is an odd integer, ties can be broken more easily, leading to a more stable decision boundary. However, for binary classification problems, using an even \\( k \\) may provide better performance by reducing the risk of ties.\r\n",
    "\r\n",
    "4. **Domain Knowledge**: Consider the characteristics of the dataset and the problem domain when choosing the value of \\( k \\). For example, if the dataset is noisy, choosing a larger \\( k \\) may help in reducing the impact of outliers. Similarly, if the classes are well-separated, a smaller \\( k \\) may suffice.\r\n",
    "\r\n",
    "5. **Rule of Thumb**: A common rule of thumb is to choose \\( k \\) as the square root of the number of samples in the training set. However, this rule may not always yield the best results and should be used as a starting point for experimentation.\r\n",
    "\r\n",
    "6. **Experimentation**: Experiment with different values of \\( k \\) and evaluate the model's performance on a validation set or through cross-validation. Visualize the decision boundaries for different values of \\( k \\) to understand how they affect the model's behavior.\r\n",
    "\r\n",
    "7. **Domain-Specific Considerations**: Consider any domain-specific constraints or requirements when choosing the value of \\( k \\). For example, in applications where computational efficiency is critical, choosing a smaller \\( k \\) may be preferred.\r\n",
    "\r\n",
    "Overall, choosing the value of \\( k \\) in K Nearest Neighbors requires a combination of empirical experimentation, cross-validation, and domain knowledge. It's essential to strike a balance between bias and variance while ensuring good generalization performance\n",
    "## When do we use KNN?\n",
    "K Nearest Neighbors (KNN) is a versatile machine learning algorithm that can be used in various scenarios. Here are some common situations where KNN is suitable:\r\n",
    "\r\n",
    "1. **Classification Tasks**: KNN is often used for classification tasks, especially in scenarios where decision boundaries are complex or nonlinear. It can effectively classify data points into multiple classes based on their proximity to neighboring data points.\r\n",
    "\r\n",
    "2. **Regression Tasks**: KNN can also be applied to regression tasks, where the goal is to predict continuous target variables. In regression, KNN predicts the target value of a new data point by averaging the target values of its nearest neighbors.\r\n",
    "\r\n",
    "3. **Small to Medium-Sized Datasets**: KNN performs well on small to medium-sized datasets with a moderate number of features and samples. It can handle datasets with complex relationships between features and target variables without the need for complex assumptions about the underlying data distribution.\r\n",
    "\r\n",
    "4. **Non-parametric Learning**: KNN is a non-parametric method, meaning it does not make any assumptions about the underlying data distribution. It is suitable for situations where the data distribution is unknown or cannot be modeled easily using parametric methods.\r\n",
    "\r\n",
    "5. **Multi-Class Classification**: KNN naturally extends to multi-class classification tasks by considering the majority class among the k nearest neighbors. It is effective in scenarios with multiple classes and imbalanced class distributions.\r\n",
    "\r\n",
    "6. **Anomaly Detection**: KNN can be used for anomaly detection by identifying data points that are significantly different from their neighbors. Anomalies are often detected as data points with few or no neighboring points within a certain distance threshold.\r\n",
    "\r\n",
    "7. **Recommender Systems**: KNN-based collaborative filtering is commonly used in recommender systems to make personalized recommendations to users based on their similarity to other users or items.\r\n",
    "\r\n",
    "8. **Initial Model Exploration**: KNN can be used as a baseline model or for initial exploratory analysis of the dataset before applying more complex algorithms. It provides a simple and intuitive approach to understanding the relationships between features and target variables.\r\n",
    "\r\n",
    "Overall, KNN is a valuable tool in a data scientist's toolkit, especially in scenarios where the data distribution is complex, and the underlying relationships are not well-defined. However, it's essential to consider its limitations, such as computational complexity and sensitivity to the choice of hyperparameters, when deciding whether to use KNN for a particular task. on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32374715-8b92-4957-8a74-cb108bd3db2b",
   "metadata": {},
   "source": [
    "## How does KNN algorithm work?:\r\n",
    "\r\n",
    "1. **Distance Metric**:\r\n",
    "   - KNN measures the distance between data points using a distance metric such as Euclidean distance, Manhattan distance, or Minkowski distance.\r\n",
    "\r\n",
    "2. **Nearest Neighbors**:\r\n",
    "   - To make a prediction for a new data point, KNN identifies the k nearest neighbors (data points) in the feature space based on the chosen distance metric.\r\n",
    "\r\n",
    "3. **Majority Vote**:\r\n",
    "   - For classification tasks, KNN predicts the class label of the new data point by taking the majority class among its k nearest neighbors.\r\n",
    "   - For regression tasks, KNN predicts the target value of the new data point by taking the average (or weighted average) of the target values of its k nearest neighbors.\r\n",
    "\r\n",
    "4. **Choosing k**:\r\n",
    "   - The value of k (number of neighbors) is a hyperparameter that needs to be specified before applying KNN. The choice of k can significantly affect the performance of the algorithm. A smaller value of k leads to a more flexible model but may be prone to noise, while a larger value of k leads to a smoother decision boundary but may oversmooh the data.\r\n",
    "\r\n",
    "### Key Concepts of KNN:\r\n",
    "\r\n",
    "- **Lazy Learner**: KNN is often referred to as a lazy learner because it does not learn a discriminative function from the training data. Instead, it memorizes the training data and makes predictions at runtime based on the stored information.\r\n",
    "\r\n",
    "- **Non-parametric Method**: KNN does not make any assumptions about the underlying data distribution and does not estimate parameters from the data.\r\n",
    "\r\n",
    "- **Distance Weighting**: In weighted KNN, the contribution of each neighbor to the prediction is weighted based on its distance from the query point. Closer neighbors have a higher influenc on the prediction.\r\n",
    "\r\n",
    "### Applications of K Nearest Neighbors:\r\n",
    "\r\n",
    "- Classification tasks (e.g., handwritten digit recognition, spam detection)\r\n",
    "- Regression tasks (e.g., predicting housing prices)\r\n",
    "- Recommender systems (e.g., movie recommendations)\r\n",
    "- Anomaly detection\r\n",
    "- Clustering (wih a variant called K-means)\r\n",
    "\r\n",
    "### Advantages of KNN:\r\n",
    "\r\n",
    "- Simple and easy to implement\r\n",
    "- No training phase (lazy learning)\r\n",
    "- Effective for small to medium-sized datasets\r\n",
    "- Handls multi-class classification tasks\r\n",
    "\r\n",
    "### Limitations of KNN:\r\n",
    "\r\n",
    "- Computationally expensive at inference time, especially for large datasets\r\n",
    "- Sensitive to the choice of distance metric and value of k\r\n",
    "- Requires careful preprocessing of data (e.g., normalization)\r\n",
    "- Not suitable for high-dimensional or sparse datasets\r\n",
    "\r\n",
    "In summary, K Nearest Neighbors is a versatile and intuitive algorithm suitable for various classification and regression tasks, especially for datasets with a well-defined distance metric and moderate size. Understanding its key concepts and parameters is crucial for effectively applying KNN in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4986f9-09fc-4d35-85db-29f6c833c75f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Use Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e82d1914-812b-4498-92d2-992fc3d0b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score # all about testing our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379fcc55-176d-45f3-9d21-716ca55b14a9",
   "metadata": {},
   "source": [
    "KNN - Predict wether a person will have diabetes or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578c96ec-16d6-444f-ba81-26142fd308d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset: 768\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "file = 'Datasets/diabetes.csv'\n",
    "dataset = pd.read_csv(file)\n",
    "print('Length of the dataset:',len(dataset))\n",
    "print(dataset.head())\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d5db45-f818-4ded-a575-64d296823c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the zero with the mean value\n",
    "zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'BMI', 'Insulin'] # make a list of the column you want to replace the zeros with\n",
    "\n",
    "# run a loop through the list that replaces the Zeros\n",
    "for column in zeros:\n",
    "    dataset[column] = dataset[column].replace(0, np.NaN) # replaces all the Zeros in each columns with NaN\n",
    "    mean = int(dataset[column].mean(skipna=True)) # Taking the mean of integer values in each columns\n",
    "    dataset[column] = dataset[column].replace(np.NaN, mean) # Replacing the NaN values with the mean\n",
    "\n",
    "# Basically, we are trying to get rid of value with no input i.e cells that has the value Zero in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61743cb2-be61-4621-b567-7c1157fbd91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>2</td>\n",
       "      <td>108.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.158</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2</td>\n",
       "      <td>146.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.337</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>7</td>\n",
       "      <td>159.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.383</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>7</td>\n",
       "      <td>168.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.787</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>3</td>\n",
       "      <td>122.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.254</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.249</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0.127</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2</td>\n",
       "      <td>146.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.329</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>10</td>\n",
       "      <td>115.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.022</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>42.7</td>\n",
       "      <td>0.559</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "624            2    108.0           64.0           29.0    155.0  30.8   \n",
       "296            2    146.0           70.0           38.0    360.0  28.0   \n",
       "192            7    159.0           66.0           29.0    155.0  30.4   \n",
       "612            7    168.0           88.0           42.0    321.0  38.2   \n",
       "272            3    122.0           78.0           29.0    155.0  23.0   \n",
       "252            2     90.0           80.0           14.0     55.0  24.4   \n",
       "328            2    102.0           86.0           36.0    120.0  45.5   \n",
       "244            2    146.0           76.0           35.0    194.0  38.2   \n",
       "464           10    115.0           98.0           29.0    155.0  24.0   \n",
       "354            3     90.0           78.0           29.0    155.0  42.7   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "624                     0.158   21        0  \n",
       "296                     0.337   29        1  \n",
       "192                     0.383   36        1  \n",
       "612                     0.787   40        1  \n",
       "272                     0.254   40        0  \n",
       "252                     0.249   24        0  \n",
       "328                     0.127   23        1  \n",
       "244                     0.329   29        0  \n",
       "464                     1.022   34        0  \n",
       "354                     0.559   21        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c829990-62c9-4a0d-af53-cad39f1e8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the dependent and independent variables\n",
    "x = dataset.iloc[:, 0:8] # or we could use dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bbe6993-48b0-49fb-a1aa-5bba4bc5e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edcf68dc-163e-4e22-96cb-2e79bd924b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xx = dataset.iloc[:, 0:8].values # or we could use dataset.iloc[:, :-1]\\nyy = dataset.iloc[:, 8].values'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''xx = dataset.iloc[:, 0:8].values # or we could use dataset.iloc[:, :-1]\n",
    "yy = dataset.iloc[:, 8].values'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2922978a-1079-41ba-9a3f-f18613e34f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f51eb544-bd14-4431-b4b9-061d415ede40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.409673645990857"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(len(y_test)) \n",
    "# The purpose of this is to know the value of K we are going to use in the next code\n",
    "# You would want to get an odd number but if you get an even number, either you add 1 or subtract 1 from the value\n",
    "# In the next block of code, i'm going to be subtracting 1 from this value and youll be seeing the value 11 in the n_neighors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5258adf-a96c-42b2-bcf6-df2c07347ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=11)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=11)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_neighbors=11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting KNN Algorithm to the Training set\n",
    "classifier = KNeighborsClassifier(n_neighbors=11, p=2, metric='euclidean') # creates an instance of logistic regression\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d1c85c9-012b-4c32-a467-300a3370bc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "y_pred = classifier.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb254b0-cb36-4821-92e3-0108524b06ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[94 13]\n",
      " [15 32]]\n",
      "f1_score: 0.6956521739130436\n",
      "accuracy_score: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:\\n',cm)\n",
    "print('f1_score:',f1_score(y_test, y_pred))\n",
    "print('accuracy_score:',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56006670-9589-4d36-8566-cf69016c2ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset: 768\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "(768, 9)\n",
      "Confusion Matrix:\n",
      " [[94 13]\n",
      " [15 32]]\n",
      "f1_score: 0.6956521739130436\n",
      "accuracy_score: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score # all about testing our model\n",
    "# load the data\n",
    "file = r\"C:\\Users\\DELL\\Data Science Library\\Machine Learning\\Datasets\\diabetes.csv\"\n",
    "dataset = pd.read_csv(file)\n",
    "print('Length of the dataset:',len(dataset))\n",
    "print(dataset.head())\n",
    "print(dataset.shape)\n",
    "# Replacing the zero with the mean value\n",
    "zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'BMI', 'Insulin'] # make a list of the column you want to replace the zeros with\n",
    "\n",
    "# run a loop through the list that replaces the Zeros\n",
    "for column in zeros:\n",
    "    dataset[column] = dataset[column].replace(0, np.NaN) # replaces all the Zeros in each columns with NaN\n",
    "    mean = int(dataset[column].mean(skipna=True)) # Taking the mean of integer values in each columns\n",
    "    dataset[column] = dataset[column].replace(np.NaN, mean) # Replacing the NaN values with the mean\n",
    "\n",
    "# Basically, we are trying to get rid of value with no input i.e cells that has the value Zero in it\n",
    "# extracting the dependent and independent variables\n",
    "x = dataset.iloc[:, 0:8] # or we could use dataset.iloc[:, :-1]\n",
    "y = dataset.iloc[:, 8]\n",
    "# splitting the dataset into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "# Feature scaling\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)\n",
    "import math\n",
    "math.sqrt(len(y_test)) \n",
    "# The purpose of this is to know the value of K we are going to use in the next code\n",
    "# You would want to get an odd number but if you get an even number, either you add 1 or subtract 1 from the value\n",
    "# In the next block of code, i'm going to be subtracting 1 from this value and youll be seeing the value 11 in the n_neighors\n",
    "# fitting KNN Algorithm to the Training set\n",
    "classifier = KNeighborsClassifier(n_neighbors=11, p=2, metric='euclidean') # creates an instance of logistic regression\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "y_pred\n",
    "# Evaluate Model\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:\\n',cm)\n",
    "print('f1_score:',f1_score(y_test, y_pred))\n",
    "print('accuracy_score:',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61565841-604b-4520-8d17-30ec62fcead3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Plotting the scatterplot for KNN algorithm\\nplt.figure(figsize=(10, 8))\\n\\n# Plotting points for each class in the training set\\nfor i, class_name in enumerate(np.unique(y_train)):\\n    plt.scatter(x_train[y_train == class_name, 0], x_train[y_train == class_name, 1], label=f'Class {class_name}', s=50)\\n\\n# Plotting the decision boundaries\\nh = 0.02  # step size in the mesh\\nx_min, x_max = x_train[:, 0].min() - 1, x_train[:, 0].max() + 1\\ny_min, y_max = x_train[:, 1].min() - 1, x_train[:, 1].max() + 1\\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\\nZ = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\\nZ = Z.reshape(xx.shape)\\nplt.contourf(xx, yy, Z, alpha=0.4, cmap='coolwarm')\\n\\n# Adding labels and title\\nplt.xlabel('Feature 1')\\nplt.ylabel('Feature 2')\\nplt.title('KNN Decision Boundaries')\\nplt.legend()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Plotting the scatterplot for KNN algorithm\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plotting points for each class in the training set\n",
    "for i, class_name in enumerate(np.unique(y_train)):\n",
    "    plt.scatter(x_train[y_train == class_name, 0], x_train[y_train == class_name, 1], label=f'Class {class_name}', s=50)\n",
    "\n",
    "# Plotting the decision boundaries\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = x_train[:, 0].min() - 1, x_train[:, 0].max() + 1\n",
    "y_min, y_max = x_train[:, 1].min() - 1, x_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, alpha=0.4, cmap='coolwarm')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('KNN Decision Boundaries')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a38fd1be-0daa-4200-8308-963d7c1cec31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the confusion matrix heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='magma', cbar=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687fd1ca-607a-4686-b715-5ac14c3a1317",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Side track (experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "360bed0a-509d-41be-aa1a-5cf056316327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xx = dataset.iloc[:, 0:8].values # or we could use dataset.iloc[:, :-1]\\nyy = dataset.iloc[:, 8].values'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''xx = dataset.iloc[:, 0:8].values # or we could use dataset.iloc[:, :-1]\n",
    "yy = dataset.iloc[:, 8].values'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c223c6b-8532-4e90-8129-2b744fc4f4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xx_train, xx_test, yy_train, yy_test = train_test_split(xx, yy, test_size=0.2, random_state=20)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''xx_train, xx_test, yy_train, yy_test = train_test_split(xx, yy, test_size=0.2, random_state=20)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48f9e65b-3ecf-4395-b200-1cb8a01543bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clf = KNeighborsClassifier() # creates an instance of logistic regression\\nclf.fit(x_train, y_train)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''clf = KNeighborsClassifier() # creates an instance of logistic regression\n",
    "clf.fit(x_train, y_train)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83ebf646-0cf0-4a85-ad8c-9007e6b017d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_predd = clf.predict(x_test)\\ny_predd'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_predd = clf.predict(x_test)\n",
    "y_predd'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29c5c6f1-6652-4506-9ecb-d64aef520e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cm = confusion_matrix(yy_test, y_predd)\\nprint('Confusion Matrix:\\n',cm)\\nprint('f1_score:',f1_score(yy_test, y_predd))\\nprint('accuracy_score:',accuracy_score(yy_test, y_predd))\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''cm = confusion_matrix(yy_test, y_predd)\n",
    "print('Confusion Matrix:\\n',cm)\n",
    "print('f1_score:',f1_score(yy_test, y_predd))\n",
    "print('accuracy_score:',accuracy_score(yy_test, y_predd))'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
